#!/usr/bin/env python3
"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ4: åŸºæœ¬å˜èªè§£æã‚¢ãƒ—ãƒª

ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å˜èªã®å‡ºç¾é »åº¦ã‚„çµ±è¨ˆæƒ…å ±ã‚’åˆ†æã™ã‚‹ã‚¢ãƒ—ãƒªã§ã™ã€‚
æ–‡å­—åˆ—å‡¦ç†ã€ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã€è¾æ›¸æ´»ç”¨ãªã©ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ:
- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨æ–‡å­—åˆ—å‡¦ç†
- æ­£è¦è¡¨ç¾ã®åŸºæœ¬çš„ãªä½¿ç”¨
- è¾æ›¸ã‚’ä½¿ã£ãŸé›†è¨ˆå‡¦ç†
- çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—ã¨è¡¨ç¤º

å¯¾å¿œç« : basics/11_standard_library.pyå®Œäº†å¾Œ
"""

import re
import string
from collections import Counter
from pathlib import Path

class BasicWordAnalyzer:
    """åŸºæœ¬çš„ãªå˜èªè§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–"""
        self.text = ""
        self.words = []
        self.word_count = {}
        self.stats = {}
    
    def load_text_from_file(self, filename):
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        
        Args:
            filename (str): èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸæ™‚True
        """
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.text = f.read()
            print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filename}")
            return True
        except FileNotFoundError:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename}")
            return False
        except UnicodeDecodeError:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {filename}")
            return False
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_text_from_input(self):
        """æ¨™æº–å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        print("åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ç©ºè¡Œã§Enterï¼‰:")
        lines = []
        while True:
            line = input()
            if not line.strip():
                break
            lines.append(line)
        
        self.text = '\n'.join(lines)
        print("âœ… ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¾ã—ãŸ")
    
    def preprocess_text(self):
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã‚’è¡Œã†
        - å°æ–‡å­—ã«å¤‰æ›
        - å¥èª­ç‚¹ã®é™¤å»
        - å˜èªã®æŠ½å‡º
        """
        if not self.text:
            print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        # å°æ–‡å­—ã«å¤‰æ›
        text_lower = self.text.lower()
        
        # è‹±æ•°å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®ã¿ã‚’æŠ½å‡º
        # è¤‡æ•°ã®ç©ºç™½æ–‡å­—ã¯1ã¤ã®ç©ºç™½ã«ç½®æ›
        processed_text = re.sub(r'[^\w\s]', ' ', text_lower)
        processed_text = re.sub(r'\s+', ' ', processed_text)
        
        # å˜èªã«åˆ†å‰²ï¼ˆç©ºç™½ã§åŒºåˆ‡ã‚‹ï¼‰
        self.words = [word.strip() for word in processed_text.split() if word.strip()]
        
        print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†å®Œäº†: {len(self.words)}å€‹ã®å˜èªã‚’æŠ½å‡º")
        return True
    
    def count_words(self):
        """å˜èªã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if not self.words:
            print("âŒ å˜èªãŒæŠ½å‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        self.word_count = Counter(self.words)
        print(f"âœ… å˜èªã‚«ã‚¦ãƒ³ãƒˆå®Œäº†: {len(self.word_count)}ç¨®é¡ã®å˜èª")
        return True
    
    def calculate_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
        if not self.text or not self.words:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return False
        
        # åŸºæœ¬çµ±è¨ˆ
        total_chars = len(self.text)
        total_chars_no_spaces = len(self.text.replace(' ', '').replace('\n', '').replace('\t', ''))
        total_words = len(self.words)
        unique_words = len(self.word_count)
        
        # æ–‡å­—ã¨è¡Œã®çµ±è¨ˆ
        lines = self.text.split('\n')
        total_lines = len(lines)
        non_empty_lines = len([line for line in lines if line.strip()])
        
        # å˜èªé•·ã®çµ±è¨ˆ
        word_lengths = [len(word) for word in self.words]
        avg_word_length = sum(word_lengths) / len(word_lengths) if word_lengths else 0
        max_word_length = max(word_lengths) if word_lengths else 0
        min_word_length = min(word_lengths) if word_lengths else 0
        
        # èªå½™ã®è±Šå¯Œã•ï¼ˆType-Token Ratioï¼‰
        ttr = unique_words / total_words if total_words > 0 else 0
        
        self.stats = {
            'total_characters': total_chars,
            'total_characters_no_spaces': total_chars_no_spaces,
            'total_words': total_words,
            'unique_words': unique_words,
            'total_lines': total_lines,
            'non_empty_lines': non_empty_lines,
            'average_word_length': avg_word_length,
            'max_word_length': max_word_length,
            'min_word_length': min_word_length,
            'type_token_ratio': ttr
        }
        
        print("âœ… çµ±è¨ˆè¨ˆç®—å®Œäº†")
        return True
    
    def get_most_common_words(self, n=10):
        """
        æœ€ã‚‚é »å‡ºã™ã‚‹å˜èªã‚’å–å¾—
        
        Args:
            n (int): å–å¾—ã™ã‚‹å˜èªæ•°
            
        Returns:
            list: (å˜èª, å‡ºç¾å›æ•°) ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ
        """
        if not self.word_count:
            return []
        
        return self.word_count.most_common(n)
    
    def get_words_by_length(self, length):
        """
        æŒ‡å®šã—ãŸé•·ã•ã®å˜èªã‚’å–å¾—
        
        Args:
            length (int): å˜èªã®é•·ã•
            
        Returns:
            list: æŒ‡å®šã—ãŸé•·ã•ã®å˜èªã®ãƒªã‚¹ãƒˆ
        """
        return [word for word in self.word_count.keys() if len(word) == length]
    
    def search_words(self, pattern):
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã™ã‚‹å˜èªã‚’æ¤œç´¢
        
        Args:
            pattern (str): æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ­£è¦è¡¨ç¾å¯¾å¿œï¼‰
            
        Returns:
            list: ãƒãƒƒãƒã—ãŸå˜èªã®ãƒªã‚¹ãƒˆ
        """
        try:
            regex = re.compile(pattern, re.IGNORECASE)
            matches = []
            for word in self.word_count.keys():
                if regex.search(word):
                    matches.append((word, self.word_count[word]))
            
            # å‡ºç¾å›æ•°ã§ã‚½ãƒ¼ãƒˆ
            matches.sort(key=lambda x: x[1], reverse=True)
            return matches
            
        except re.error as e:
            print(f"âŒ æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def analyze_all(self):
        """ã™ã¹ã¦ã®è§£æã‚’å®Ÿè¡Œ"""
        if not self.text:
            print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        success = (
            self.preprocess_text() and
            self.count_words() and
            self.calculate_statistics()
        )
        
        if success:
            print("ğŸ‰ è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        return success

class WordAnalyzerUI:
    """å˜èªè§£æã‚¢ãƒ—ãƒªã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def __init__(self):
        """UIã‚’åˆæœŸåŒ–"""
        self.analyzer = BasicWordAnalyzer()
    
    def show_welcome(self):
        """ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸ“Š åŸºæœ¬å˜èªè§£æã‚¢ãƒ—ãƒª")
        print("=" * 60)
        print("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å˜èªã‚’åˆ†æã—ã€çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™")
        print("=" * 60)
    
    def show_main_menu(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤º"""
        print("\nğŸ“‹ ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        print("-" * 40)
        print("1. ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿")
        print("2. ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›")
        print("3. åŸºæœ¬çµ±è¨ˆã‚’è¡¨ç¤º")
        print("4. é »å‡ºå˜èªã‚’è¡¨ç¤º")
        print("5. å˜èªã‚’æ¤œç´¢")
        print("6. é•·ã•åˆ¥å˜èªè¡¨ç¤º")
        print("7. è©³ç´°è§£æçµæœã‚’è¡¨ç¤º")
        print("8. çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜")
        print("0. çµ‚äº†")
        print("-" * 40)
    
    def load_file_interactive(self):
        """å¯¾è©±å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        print("\nğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
        print("-" * 30)
        
        filename = input("ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›: ").strip()
        if not filename:
            print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        if self.analyzer.load_text_from_file(filename):
            self.analyzer.analyze_all()
    
    def input_text_interactive(self):
        """å¯¾è©±å¼ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›"""
        print("\nâœï¸ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›")
        print("-" * 30)
        
        self.analyzer.load_text_from_input()
        self.analyzer.analyze_all()
    
    def show_basic_stats(self):
        """åŸºæœ¬çµ±è¨ˆã‚’è¡¨ç¤º"""
        if not self.analyzer.stats:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        stats = self.analyzer.stats
        
        print("\nğŸ“Š åŸºæœ¬çµ±è¨ˆæƒ…å ±")
        print("=" * 40)
        print(f"ğŸ“ ç·æ–‡å­—æ•°:         {stats['total_characters']:,}")
        print(f"ğŸ“ æ–‡å­—æ•°(ç©ºç™½é™¤ã):  {stats['total_characters_no_spaces']:,}")
        print(f"ğŸ“° ç·è¡Œæ•°:           {stats['total_lines']:,}")
        print(f"ğŸ“° éç©ºè¡Œæ•°:         {stats['non_empty_lines']:,}")
        print(f"ğŸ”¤ ç·å˜èªæ•°:         {stats['total_words']:,}")
        print(f"ğŸ”¤ ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°:   {stats['unique_words']:,}")
        print(f"ğŸ“ å¹³å‡å˜èªé•·:       {stats['average_word_length']:.2f}")
        print(f"ğŸ“ æœ€å¤§å˜èªé•·:       {stats['max_word_length']}")
        print(f"ğŸ“ æœ€å°å˜èªé•·:       {stats['min_word_length']}")
        print(f"ğŸ“ˆ èªå½™è±Šå¯Œåº¦(TTR):  {stats['type_token_ratio']:.3f}")
        print("=" * 40)
    
    def show_frequent_words(self):
        """é »å‡ºå˜èªã‚’è¡¨ç¤º"""
        if not self.analyzer.word_count:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        try:
            n = int(input("è¡¨ç¤ºã™ã‚‹å˜èªæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:10): ") or "10")
        except ValueError:
            n = 10
        
        most_common = self.analyzer.get_most_common_words(n)
        
        print(f"\nğŸ” é »å‡ºå˜èª TOP {n}")
        print("=" * 40)
        for i, (word, count) in enumerate(most_common, 1):
            percentage = (count / self.analyzer.stats['total_words']) * 100
            print(f"{i:2d}. {word:<15} {count:>5}å› ({percentage:5.2f}%)")
        print("=" * 40)
    
    def search_words_interactive(self):
        """å¯¾è©±å¼ã§å˜èªã‚’æ¤œç´¢"""
        if not self.analyzer.word_count:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        print("\nğŸ” å˜èªæ¤œç´¢")
        print("-" * 30)
        print("ğŸ’¡ æ­£è¦è¡¨ç¾ã‚‚ä½¿ç”¨ã§ãã¾ã™")
        print("ä¾‹: '^a' (aã§å§‹ã¾ã‚‹), 'ing$' (ingã§çµ‚ã‚ã‚‹), '.{5,}' (5æ–‡å­—ä»¥ä¸Š)")
        
        pattern = input("æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: ").strip()
        if not pattern:
            print("âŒ æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        matches = self.analyzer.search_words(pattern)
        
        if not matches:
            print(f"ğŸ“ ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã«ãƒãƒƒãƒã™ã‚‹å˜èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print(f"\nğŸ” æ¤œç´¢çµæœ: '{pattern}' ({len(matches)}ä»¶)")
        print("=" * 40)
        for word, count in matches[:20]:  # æœ€å¤§20ä»¶è¡¨ç¤º
            print(f"{word:<20} {count:>3}å›")
        
        if len(matches) > 20:
            print(f"... ä»– {len(matches) - 20} ä»¶")
        print("=" * 40)
    
    def show_words_by_length(self):
        """é•·ã•åˆ¥ã«å˜èªã‚’è¡¨ç¤º"""
        if not self.analyzer.word_count:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        try:
            length = int(input("å˜èªã®é•·ã•: "))
        except ValueError:
            print("âŒ æœ‰åŠ¹ãªæ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        words = self.analyzer.get_words_by_length(length)
        
        if not words:
            print(f"ğŸ“ {length}æ–‡å­—ã®å˜èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # å‡ºç¾å›æ•°ã§ã‚½ãƒ¼ãƒˆ
        words_with_count = [(word, self.analyzer.word_count[word]) for word in words]
        words_with_count.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ“ {length}æ–‡å­—ã®å˜èª ({len(words)}ä»¶)")
        print("=" * 40)
        for word, count in words_with_count[:20]:  # æœ€å¤§20ä»¶è¡¨ç¤º
            print(f"{word:<20} {count:>3}å›")
        
        if len(words_with_count) > 20:
            print(f"... ä»– {len(words_with_count) - 20} ä»¶")
        print("=" * 40)
    
    def show_detailed_analysis(self):
        """è©³ç´°è§£æçµæœã‚’è¡¨ç¤º"""
        if not self.analyzer.word_count:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        print("\nğŸ“ˆ è©³ç´°è§£æçµæœ")
        print("=" * 50)
        
        # åŸºæœ¬çµ±è¨ˆ
        self.show_basic_stats()
        
        # å˜èªé•·åˆ†å¸ƒ
        print("\nğŸ“Š å˜èªé•·åˆ†å¸ƒ")
        print("-" * 30)
        length_dist = {}
        for word in self.analyzer.words:
            length = len(word)
            length_dist[length] = length_dist.get(length, 0) + 1
        
        for length in sorted(length_dist.keys()):
            count = length_dist[length]
            percentage = (count / len(self.analyzer.words)) * 100
            bar = "â–ˆ" * int(percentage / 2)  # ç°¡å˜ãªãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            print(f"{length:2d}æ–‡å­—: {count:4d}å€‹ ({percentage:5.1f}%) {bar}")
        
        # é »å‡ºå˜èª
        print(f"\nğŸ” é »å‡ºå˜èª TOP 5")
        print("-" * 30)
        for i, (word, count) in enumerate(self.analyzer.get_most_common_words(5), 1):
            percentage = (count / self.analyzer.stats['total_words']) * 100
            print(f"{i}. {word} ({count}å›, {percentage:.1f}%)")
    
    def save_results_to_file(self):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not self.analyzer.stats:
            print("âŒ ã¾ãšãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            return
        
        filename = input("ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:analysis_result.txt): ").strip()
        if not filename:
            filename = "analysis_result.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("=== å˜èªè§£æçµæœ ===\n\n")
                
                # åŸºæœ¬çµ±è¨ˆ
                stats = self.analyzer.stats
                f.write("ğŸ“Š åŸºæœ¬çµ±è¨ˆæƒ…å ±\n")
                f.write("-" * 30 + "\n")
                f.write(f"ç·æ–‡å­—æ•°: {stats['total_characters']:,}\n")
                f.write(f"ç·å˜èªæ•°: {stats['total_words']:,}\n")
                f.write(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°: {stats['unique_words']:,}\n")
                f.write(f"å¹³å‡å˜èªé•·: {stats['average_word_length']:.2f}\n")
                f.write(f"èªå½™è±Šå¯Œåº¦: {stats['type_token_ratio']:.3f}\n\n")
                
                # é »å‡ºå˜èª
                f.write("ğŸ” é »å‡ºå˜èª TOP 20\n")
                f.write("-" * 30 + "\n")
                for i, (word, count) in enumerate(self.analyzer.get_most_common_words(20), 1):
                    percentage = (count / stats['total_words']) * 100
                    f.write(f"{i:2d}. {word:<15} {count:>5}å› ({percentage:5.2f}%)\n")
            
            print(f"âœ… çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.show_welcome()
        
        while True:
            try:
                self.show_main_menu()
                choice = input("é¸æŠ: ").strip()
                
                if choice == "1":
                    self.load_file_interactive()
                elif choice == "2":
                    self.input_text_interactive()
                elif choice == "3":
                    self.show_basic_stats()
                elif choice == "4":
                    self.show_frequent_words()
                elif choice == "5":
                    self.search_words_interactive()
                elif choice == "6":
                    self.show_words_by_length()
                elif choice == "7":
                    self.show_detailed_analysis()
                elif choice == "8":
                    self.save_results_to_file()
                elif choice == "0":
                    print("\nğŸ‘‹ å˜èªè§£æã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¾ã™")
                    break
                else:
                    print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
                
                input("\nEnterã‚­ãƒ¼ã§ç¶šè¡Œ...")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å˜èªè§£æã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¾ã™")
                break
            except Exception as e:
                print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                input("Enterã‚­ãƒ¼ã§ç¶šè¡Œ...")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    app = WordAnalyzerUI()
    app.run()

if __name__ == "__main__":
    main()

"""
ğŸ¯ å­¦ç¿’ã®ãƒã‚¤ãƒ³ãƒˆ:

1. æ–‡å­—åˆ—å‡¦ç†
   - æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ãŸãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
   - å¤§æ–‡å­—å°æ–‡å­—ã®å¤‰æ›
   - å˜èªã®æŠ½å‡ºã¨åˆ†å‰²

2. ãƒ•ã‚¡ã‚¤ãƒ«I/O
   - ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨ãªèª­ã¿è¾¼ã¿
   - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å‡¦ç†
   - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

3. ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
   - Counterã‚¯ãƒ©ã‚¹ã‚’ä½¿ã£ãŸé›†è¨ˆ
   - è¾æ›¸ã«ã‚ˆã‚‹é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
   - çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—

4. æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
   - æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ãŸæ¤œç´¢
   - æ¡ä»¶ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
   - ã‚½ãƒ¼ãƒˆã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°

ğŸ”§ æ”¹è‰¯æ¡ˆ:
- ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»æ©Ÿèƒ½
- è¨€èªåˆ¤å®šæ©Ÿèƒ½
- ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ©Ÿèƒ½
- é¡ä¼¼åº¦åˆ†æ
- æ„Ÿæƒ…åˆ†æ

âš¡ å®Ÿè¡Œæ–¹æ³•:
python3 projects/04_word_analyzer/basic_analyzer.py

ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼
"""